{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quQPiNBeM2X6"
      },
      "outputs": [],
      "source": [
        "# The Natural Language Toolkit (nltk) is a library in Python that provides tools to work with human language data. It includes modules for text processing, such as tokenization, stemming, and tagging, as well as modules for semantic reasoning, such as parsing and semantic interpretation.\n",
        "\n",
        "# Here's an example of how to use nltk to tokenize a sentence:\n",
        "# Install nltk by running pip install nltk in your terminal or command prompt.\n",
        "\n",
        "# Import the library by running import nltk in your Python script.\n",
        "\n",
        "# Download the necessary data by running nltk.download() in your Python script. This will open a download window where you can select the data you want to download. For this tutorial, you will need to download the \"punkt\" package, which is a pre-trained model for tokenizing text into sentences and words.\n",
        "\n",
        "# Tokenize a sentence by running the following code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = \"This is a simple sentence.\"\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "id": "Xw_EdJYVNrF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will output ['This', 'is', 'a', 'simple', 'sentence', '.']\n",
        "\n",
        "# Perform POS (Part-of-Speech) tagging by running the following code:\n",
        "from nltk import pos_tag\n",
        "\n",
        "tagged = pos_tag(tokens)\n",
        "print(tagged)\n"
      ],
      "metadata": {
        "id": "jNrG3JYONvLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will output [('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('simple', 'JJ'), ('sentence', 'NN'), ('.', '.')]\n",
        "\n",
        "# Perform stemming by running the following code:\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
        "print(stemmed_words)\n"
      ],
      "metadata": {
        "id": "Uc11GLqnN0fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will output ['thi', 'is', 'a', 'simpl', 'sentenc', '.']\n",
        "\n",
        "# Perform lemmatization by running the following code:\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(lemmatized_words)\n"
      ],
      "metadata": {
        "id": "6KINp61EN49A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will output ['This', 'is', 'a', 'simple', 'sentence', '.']\n",
        "\n",
        "# This is just a small sample of what you can do with nltk. The library offers a wide range of functionality, including but not limited to text classification, information extraction, language translation and more.\n",
        "\n"
      ],
      "metadata": {
        "id": "htJT4dJhN_jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Download necessary data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define input sentence\n",
        "sentence = \"This is a simple sentence.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = word_tokenize(sentence)\n",
        "print(\"Tokenized Sentence: \", tokens)\n",
        "\n",
        "# Perform POS tagging\n",
        "tagged = pos_tag(tokens)\n",
        "print(\"POS Tagged Sentence: \", tagged)\n",
        "\n",
        "# Perform stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
        "print(\"Stemmed Sentence: \", stemmed_words)\n",
        "\n",
        "# Perform lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(\"Lemmatized Sentence: \", lemmatized_words)\n"
      ],
      "metadata": {
        "id": "RtpXC5QcOHbH"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}